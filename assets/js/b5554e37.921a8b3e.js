"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[465],{4168:(e,n,s)=>{s.d(n,{A:()=>i});const i=s.p+"assets/images/chat-interface-55405bce605bf63d945fc7e238952cf5.png"},5245:(e,n,s)=>{s.d(n,{A:()=>i});const i=s.p+"assets/images/Knowledge-Base-Configuration-Lower-Section-e253684361c00bd77ac01ec83d8b3743.png"},5730:(e,n,s)=>{s.d(n,{A:()=>i});const i=s.p+"assets/images/citation-example-4eb8da327d226c5efa91d1225cbfbff0.png"},6552:(e,n,s)=>{s.d(n,{A:()=>i});const i=s.p+"assets/images/Knowledge-Base-Config-Now-0940bd38107b36614fa11696e4494eb5.png"},8453:(e,n,s)=>{s.d(n,{R:()=>t,x:()=>l});var i=s(6540);const r={},o=i.createContext(r);function t(e){const n=i.useContext(o);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:t(e.components),i.createElement(o.Provider,{value:n},e.children)}},8620:(e,n,s)=>{s.d(n,{A:()=>i});const i=s.p+"assets/images/response-example-13ad7658167ce3385da3235328504907.png"},9152:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>d,contentTitle:()=>l,default:()=>h,frontMatter:()=>t,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"RAG-Chat","title":"RAG-Chat","description":"Our advanced vision-based multimodal RAG-Chat system enables AI-powered conversations with flexible knowledge integration. Choose from these interaction modes:","source":"@site/docs/RAG-Chat.md","sourceDirName":".","slug":"/RAG-Chat","permalink":"/layra/docs/RAG-Chat","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Knowledge Base","permalink":"/layra/docs/knowledge-base"},"next":{"title":"Workflow","permalink":"/layra/docs/category/workflow"}}');var r=s(4848),o=s(8453);const t={sidebar_position:3},l="RAG-Chat",d={},c=[{value:"Configuring Knowledge Base and LLM",id:"configuring-knowledge-base-and-llm",level:2},{value:"Configuration Panel - Upper Section",id:"configuration-panel---upper-section",level:3},{value:"Configuration Panel - Lower Section",id:"configuration-panel---lower-section",level:3},{value:"Chat Interface",id:"chat-interface",level:2},{value:"Standard Chat (No RAG)",id:"standard-chat-no-rag",level:3},{value:"RAG Mode",id:"rag-mode",level:3},{value:"Conversation History",id:"conversation-history",level:2},{value:"Next Steps",id:"next-steps",level:2}];function a(e){const n={admonition:"admonition",br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",img:"img",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"rag-chat",children:"RAG-Chat"})}),"\n",(0,r.jsxs)(n.p,{children:["Our advanced ",(0,r.jsx)(n.strong,{children:"vision-based multimodal RAG-Chat system"})," enables ",(0,r.jsx)(n.strong,{children:"AI-powered conversations"})," with flexible knowledge integration. Choose from these interaction modes:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Standard conversations without RAG"}),"\n",(0,r.jsx)(n.li,{children:"RAG-enabled conversations using single or multiple knowledge bases"}),"\n",(0,r.jsx)(n.li,{children:"Instant RAG conversations with uploaded files"}),"\n",(0,r.jsx)(n.li,{children:"Hybrid mode combining document uploads with knowledge base retrieval"}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsxs)(n.p,{children:["Before proceeding, ensure you've configured your preferred LLM and knowledge base by clicking the ",(0,r.jsx)(n.strong,{children:"Config Now"})," button in the center-right section."]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"configuring-knowledge-base-and-llm",children:"Configuring Knowledge Base and LLM"}),"\n",(0,r.jsxs)(n.p,{children:["Click the ",(0,r.jsx)(n.strong,{children:"Config Now"})," button (center-right section) to access the Knowledge Base Configuration panel.",(0,r.jsx)(n.br,{}),"\n",(0,r.jsx)(n.img,{alt:"Knowledge Base Configuration - Config Now",src:s(6552).A+"",width:"3024",height:"1964"})]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h3,{id:"configuration-panel---upper-section",children:"Configuration Panel - Upper Section"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Knowledge Base Configuration - Upper Section",src:s(9894).A+"",width:"3024",height:"1964"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Add Knowledge-Base"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Redirects to the knowledge base management interface (refer to previous tutorial section)"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"LLM Settings Section"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"LLM Engine"}),": Select your preferred large language model"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Add New Configuration"}),": Create custom LLM configurations (supports OpenAI-compatible APIs)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"LLM Url"}),": Endpoint URL for OpenAI-compatible APIs"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"API Key"}),": Your LLM service authentication key"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Knowledge Base Selection"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Multi-select knowledge bases using checkboxes"}),"\n"]}),"\n",(0,r.jsxs)(n.admonition,{title:"LOCAL DEPLOYMENT NOTE",type:"important",children:[(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"When using locally hosted models:"})}),(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["The ",(0,r.jsx)(n.strong,{children:"API Key"})," field accepts any placeholder text."]}),"\n",(0,r.jsxs)(n.li,{children:["Set the LLM URL to your machine's ",(0,r.jsx)(n.strong,{children:"Internal IP Address"})," (e.g., ",(0,r.jsx)(n.code,{children:"http://192.168.1.5:8000"})," or ",(0,r.jsx)(n.code,{children:"http://10.0.0.2:5000"}),") instead of ",(0,r.jsx)(n.code,{children:"localhost"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Firewall Configuration:"})," If using a firewall (e.g., ",(0,r.jsx)(n.code,{children:"ufw"}),"), allow Docker network access to your LLM port."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Service Binding:"})," Ensure your LLM service ",(0,r.jsxs)(n.strong,{children:["binds to ",(0,r.jsx)(n.code,{children:"0.0.0.0"})]})," (all interfaces) instead of ",(0,r.jsx)(n.code,{children:"127.0.0.1"})," (localhost only)."]}),"\n"]})]}),"\n",(0,r.jsx)(n.admonition,{title:"SYSTEM REQUIREMENT",type:"tip",children:(0,r.jsx)(n.p,{children:"LAYRA's vision-based multimodal RAG system requires your LLM to support visual inputs (VLM capability) for full RAG functionality."})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h3,{id:"configuration-panel---lower-section",children:"Configuration Panel - Lower Section"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Knowledge Base Configuration - Lower Section",src:s(5245).A+"",width:"3024",height:"1964"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"System Prompt"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Contains the LLM's system instructions (Pro Tip: Well-crafted prompts significantly improve response quality)"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Advanced Settings"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Use Model Default"}),": Applies default server-side configurations","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"LLM: Preserves original model parameters"}),"\n",(0,r.jsx)(n.li,{children:"RAG: Defaults to Top-K=3 and Score Threshold=10"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Temperature"})," (0-1): Controls response creativity"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Max Token"})," (1024-1048576): Response length limit"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Top-P"})," (0-1): Probability mass sampling parameter"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Knowledge-Base Top-K"})," (1-30): Retrieved passages quantity"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Retrieval Score Threshold"})," (0-20): Minimum relevance score"]}),"\n"]}),"\n",(0,r.jsxs)(n.admonition,{title:"RECOMMENDATIONS",type:"tip",children:[(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"For Beginners"}),":"]}),(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Default settings provide optimal balance for most use cases"}),"\n",(0,r.jsxs)(n.li,{children:["Each +1 in ",(0,r.jsx)(n.strong,{children:"Top-K"})," adds ~1000 tokens - adjust according to your compute resources"]}),"\n",(0,r.jsxs)(n.li,{children:["Recommended ",(0,r.jsx)(n.strong,{children:"Top-K"})," values: 10 (resource-rich) or 3 (resource-constrained)"]}),"\n"]}),(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"For Learners"}),":"]}),(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Consult your LLM to understand each advanced parameter's effect through interactive Q&A"}),"\n"]})]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"chat-interface",children:"Chat Interface"}),"\n",(0,r.jsxs)(n.p,{children:["After configuring and saving your LLM and knowledge base settings, you're ready to start conversations. The current LLM and selected knowledge bases will be displayed below the ",(0,r.jsx)(n.strong,{children:"Config Now"})," button."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Chat Interface",src:s(4168).A+"",width:"3024",height:"1964"})}),"\n",(0,r.jsx)(n.p,{children:"LAYRA supports the following conversation modes with identical user experience:"}),"\n",(0,r.jsx)(n.h3,{id:"standard-chat-no-rag",children:"Standard Chat (No RAG)"}),"\n",(0,r.jsx)(n.p,{children:"When no files are uploaded and no knowledge bases selected:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Pure LLM conversation"}),"\n",(0,r.jsx)(n.li,{children:"No knowledge base integration"}),"\n",(0,r.jsx)(n.li,{children:"Fastest response time"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"rag-mode",children:"RAG Mode"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Single Knowledge Base"}),":\nWhen selecting one knowledge base:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Retrieves from one selected source"}),"\n",(0,r.jsx)(n.li,{children:"Best for focused topics"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Multiple Knowledge Bases"}),":\nWhen selecting multiple knowledge bases:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Combine information from several sources"}),"\n",(0,r.jsx)(n.li,{children:"Enable by checking multiple Knowledge Bases in sidebar"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Temporary Files"}),":\nWhen uploading files:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Use uploaded files just for current chat"}),"\n",(0,r.jsx)(n.li,{children:"Doesn't affect permanent knowledge bases"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Hybrid Mode (Files + Knowledge Bases)"}),":\nWhen uploading files AND selecting knowledge bases:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Combines temporary files with permanent knowledge bases"}),"\n",(0,r.jsx)(n.li,{children:"Provides most comprehensive context"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Response Example",src:s(8620).A+"",width:"3024",height:"1964"})}),"\n",(0,r.jsx)(n.p,{children:"The chat interface displays the current LLM and called knowledge bases above each response."}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Citation Example",src:s(5730).A+"",width:"3024",height:"1964"})}),"\n",(0,r.jsx)(n.p,{children:"Responses include token usage statistics and RAG citations at the end, sorted by relevance with:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Relevance score"}),"\n",(0,r.jsx)(n.li,{children:"Document source"}),"\n",(0,r.jsx)(n.li,{children:"Knowledge base origin"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Token Usage Breakdown"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Total token usage"}),"\n",(0,r.jsx)(n.li,{children:"Completion token usage"}),"\n",(0,r.jsx)(n.li,{children:"Prompt token usage"}),"\n"]}),"\n",(0,r.jsxs)(n.admonition,{title:"NOTE",type:"important",children:[(0,r.jsx)(n.p,{children:"LAYRA applies score threshold filtering to both uploaded files and knowledge base retrievals. Only content scoring above the threshold will be recalled."}),(0,r.jsx)(n.p,{children:"To analyze complete documents:"}),(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Set score threshold to 0"}),"\n",(0,r.jsx)(n.li,{children:"Ensure Top-K exceeds document page count"}),"\n"]})]}),"\n",(0,r.jsx)(n.h2,{id:"conversation-history",children:"Conversation History"}),"\n",(0,r.jsx)(n.p,{children:"Access previous conversations via the left sidebar:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Click conversations to view history"}),"\n",(0,r.jsx)(n.li,{children:"Click the three-dot menu to rename or delete conversations"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"History Interface",src:s(9948).A+"",width:"3024",height:"1964"})}),"\n",(0,r.jsx)(n.admonition,{title:"WARNING",type:"danger",children:(0,r.jsx)(n.p,{children:"Deleted conversations cannot be recovered."})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,r.jsxs)(n.p,{children:["Explore LAYRA's most powerful feature - ",(0,r.jsx)(n.strong,{children:"Agent Workflow Orchestration"})," with visual RAG capabilities."]})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(a,{...e})}):a(e)}},9894:(e,n,s)=>{s.d(n,{A:()=>i});const i=s.p+"assets/images/Knowledge-Base-Configuration-Upper-Section-9446fb0dd6a6fe1029d415861fefa5c0.png"},9948:(e,n,s)=>{s.d(n,{A:()=>i});const i=s.p+"assets/images/history-interface-74f96e8bcae2872de37a738103fc5432.png"}}]);